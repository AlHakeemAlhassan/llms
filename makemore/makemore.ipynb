{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['camber', 'aidy', 'rally', 'chrystopher', 'ankit']\n",
      "number of names:  32033\n",
      "(list of chars, count):  ('abcdefghijklmnopqrstuvwxyz<S><E>', 28)\n",
      "(max word length, min word length):  (15, 2)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "with open(\"names.txt\", \"r+\") as f:\n",
    "\twords = f.read().splitlines()\n",
    "\twords = [word.strip() for word in words] # get rid of any trailing spaces\n",
    "\twords = [w for w in words if w] # get rid of any empty strings\n",
    "\tnames = sorted(words, key=lambda x: random.random())\n",
    "\t\n",
    "with open(\"names.txt\", \"w\") as f: \n",
    "\tjoined = \"\\n\".join(names)\n",
    "\tf.write(joined)\n",
    "\n",
    "\n",
    "min_chars = min(len(v) for v in words)\n",
    "max_chars = max(len(v) for v in words)\n",
    "chars = sorted(list(set(\"\".join(names))))\n",
    "chars += ['<S>', '<E>']\n",
    "\n",
    "print(\"names: \", names[:5])\n",
    "print(\"number of names: \", len(names))\n",
    "print(\"(list of chars, count): \", (\"\".join(chars), len(chars)))\n",
    "print(\"(max word length, min word length): \", (max_chars, min_chars))\n",
    "\n",
    "# adding start and end token to each name\n",
    "names = [['<S>'] + list(name) + ['<E>'] for name in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max bigram occurance:  (('n', '<E>'), 6763)\n",
      "min bigram occurance:  (('z', 'x'), 1)\n"
     ]
    }
   ],
   "source": [
    "b = {}\n",
    "for name in names:\n",
    "\tfor ch1, ch2 in zip(name, name[1:]):\n",
    "\t\tbigram = (ch1, ch2)\n",
    "\t\tb[bigram] = b.get(bigram, 0) + 1\n",
    "\n",
    "b = sorted(b.items(), key = lambda kv: -kv[1])\n",
    "print(\"max bigram occurance: \", b[0])\n",
    "print(\"min bigram occurance: \", b[-1])\n",
    "b = dict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import torch\n",
    "N = []\n",
    "\n",
    "# a replacement until pytorch starts to work again\n",
    "for i in range(28):\n",
    "    N.append([])\n",
    "    for j in range(28):\n",
    "        N[i].append(1) # for smoothening the array\n",
    "assert len(N) == 28\n",
    "assert len(N[0]) == 28\n",
    "#N = torch.zeros((28, 28), dtype=torch.int32)\n",
    "\n",
    "atoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itoa = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "for name in names:\n",
    "\tfor ch1, ch2 in zip(name, name[1:]):\n",
    "\t\tix1, ix2 = atoi[ch1], atoi[ch2]\n",
    "\t\tN[ix1][ix2] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f47b0c76920>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28\n",
      "784 28\n"
     ]
    }
   ],
   "source": [
    "# Normalization of N\n",
    "import numpy as np\n",
    "P = np.array(N, dtype=np.float64)\n",
    "print(len(P[0]), len(P))\n",
    "print(P.size, P[0].size)\n",
    "for i in range(28):\n",
    "    s = P[i].sum()\n",
    "    P[i] = P[i] / s\n",
    "\n",
    "\n",
    "# normalization test\n",
    "for i in range(28):\n",
    "    assert P[i].sum() < 1.01 and P[i].sum() > 0.99, \"print \" + str(P[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'multinomial'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'multinomial'"
     ]
    }
   ],
   "source": [
    "np.multinomial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram model\n",
    "- Bigram (one character predicts the next one with a lookup table of counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m      3\u001b[0m N \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# import torch \n",
    "# torch.zeros((3, 5), dtype=torch.int32)\n",
    "# N = torch.zeros((28,28), dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNewGELU\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n",
    "    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
